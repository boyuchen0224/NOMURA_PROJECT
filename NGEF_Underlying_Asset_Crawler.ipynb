{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感謝 [Wyne_Jie](https://github.com/sefx5ever) 提供"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options  # for suppressing the browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "columns = ['no', 'bloomberg_code', 't_name', 'net_ass_val_rate', 'Date']\n",
    "allDF = pd.DataFrame(columns = columns)\n",
    "\n",
    "class nomura_monthly_target_crawler:\n",
    "    def __init__(self,date:str):\n",
    "        # Basic settings\n",
    "        self.ALL = ['201506','201507','201508','201509','201510','201511','201512','201601',\n",
    "                    '201602','201603','201604','201605','201606','201607','201608','201609',\n",
    "                    '201610','201611','201612','201701','201702','201703','201704','201705',\n",
    "                    '201706','201707','201708','201709','201710','201711','201712','201801',\n",
    "                    '201802','201803','201804','201805','201806','201807','201808','201809',\n",
    "                    '201810','201811','201812','201901','201902','201903','201904','201905',\n",
    "                    '201906','201907','201908','201909','201910','201911','201912','202001',\n",
    "                    '202002','202003']\n",
    "\n",
    "        # Get data settings\n",
    "        self.df_inv_target = ''\n",
    "        self.data_to_df = [] # Final result as a list of list\n",
    "        self.DATE = date\n",
    "        self.UNIT = 'A0032'\n",
    "        self.FUND_TYPE = 'AA2'\n",
    "\n",
    "        # Check input format\n",
    "        if date.lower() == 'all':\n",
    "            for date in self.ALL:\n",
    "                self.DATE = date\n",
    "                self.request()\n",
    "                self.to_csv()\n",
    "        elif len(date) != '6' or date not in self.ALL:\n",
    "            print('Error: Date format is wrong! It should be [YYYYMM]')\n",
    "\n",
    "    def request(self):\n",
    "        # Run without screen\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('headless')\n",
    "        # Start modify\n",
    "        self.driver = webdriver.Chrome(r'/Users/chenboyu/Desktop/野村投信/chromedriver', options = options)\n",
    "        self.driver.get(\"https://www.sitca.org.tw/ROC/Industry/IN2629.aspx\")\n",
    "        sleep(5)\n",
    "\n",
    "        # Select Date\n",
    "        self.driver.find_element_by_xpath('//option[@value=\"{}\"]'.format(self.DATE)).click()\n",
    "        sleep(2)\n",
    "\n",
    "        # Select Unit\n",
    "        self.driver.find_element_by_id('ctl00_ContentPlaceHolder1_rbComCL').click()\n",
    "        self.driver.find_element_by_xpath(\"//select[@id='ctl00_ContentPlaceHolder1_ddlQ_Comid1']/option[@value='{}']\".format(self.UNIT)).click()\n",
    "        sleep(2)\n",
    "\n",
    "        # Select Fund Type\n",
    "        self.driver.find_element_by_xpath(\"//select[@id='ctl00_ContentPlaceHolder1_ddlQ_Class1']/option[@value='{}']\".format(self.FUND_TYPE)).click()\n",
    "        sleep(2)\n",
    "\n",
    "        # Submit search\n",
    "        self.driver.find_element_by_id(\"ctl00_ContentPlaceHolder1_BtnQuery\").click()\n",
    "        self.process_data()\n",
    "\n",
    "    def process_data(self):\n",
    "        soup = bs(self.driver.page_source,'html.parser') # Clear tag after decode\n",
    "        pre_save = [] # Temporary save before create a row\n",
    "        count = 0 # Download 10 unit data then break loop\n",
    "        start_to_save = False # A switch for getting data if it's 野村美利堅高收益債基金\n",
    "        raw_data = soup.find_all('td',{ 'class' : ['DTeven','DTodd'] }) # Find tag by multiple class name\n",
    "\n",
    "        try:\n",
    "            # Start to clear and get data\n",
    "            for data in raw_data:\n",
    "                if start_to_save: # bool\n",
    "                    pre_save.append(data.string)\n",
    "                    if len(pre_save) == 9: # fulfilled condition of a rows\n",
    "                        self.data_to_df.append(pre_save)\n",
    "                        pre_save = [] # Reset temp data\n",
    "                        count+=1\n",
    "                    if count == 10: # Break if get all data\n",
    "                        break\n",
    "                if data.string == '野村環球基金': # Turn on switch for saving data\n",
    "                    start_to_save = True\n",
    "            if len(self.data_to_df) == False:\n",
    "                print(\"Error: {} doesn't have fund data!\".format(self.DATE))\n",
    "        except Exception as e:\n",
    "            print(\"Error: \" + str(e))\n",
    "\n",
    "    def to_csv(self):\n",
    "        if len(self.data_to_df) == False:\n",
    "            print(\"Error: {} doesn't have fund data!\".format(self.DATE))\n",
    "            self.driver.close()\n",
    "            return\n",
    "\n",
    "        # Create dataframe with rows and columns\n",
    "        columns = ['no','t_type','bloomberg_code','t_name','amount','guarentee_institution','s-order_bonds','num_beneficiary_unit','net_ass_val_rate']\n",
    "        self.df_inv_target = pd.DataFrame(self.data_to_df[-10:], columns = columns)\n",
    "\n",
    "        # Get the share code\n",
    "        self.df_inv_target['t_name'] = self.df_inv_target['t_name'].apply(lambda x : x.split(' ')[0])\n",
    "        # Drop the unused coloumns\n",
    "        self.df_inv_target = self.df_inv_target[['no', 'bloomberg_code', 't_name', 'net_ass_val_rate']]\n",
    "        self.df_inv_target['Date'] = self.DATE\n",
    "        global allDF\n",
    "        allDF = pd.concat([allDF, self.df_inv_target], axis = 0)\n",
    "        print('{} has benn finished'.format(self.DATE))\n",
    "        # Convert to csv\n",
    "#         self.df_inv_target.to_csv('nomura_monthly_target_{}.csv'.format(self.DATE),index = False,header = True)\n",
    "#         print('COMPLETE: nomura_monthly_target_{}.csv !'.format(self.DATE))\n",
    "        self.driver.close()\n",
    "\n",
    "################ TEST FORMAT ################\n",
    "if __name__ == \"__main__\":\n",
    "    nmr_crawler = nomura_monthly_target_crawler('all')\n",
    "    allDF.to_csv('NGEF_underlying_asset_info.csv')\n",
    "#     nmr_crawler.request()\n",
    "#     nmr_crawler.to_csv()\n",
    "    # print(nmr_crawler.df_inv_target)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
