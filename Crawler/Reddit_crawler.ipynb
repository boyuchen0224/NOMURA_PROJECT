{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import datetime as dt\n",
    "from psaw import PushshiftAPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetDfArr(year, target): # Get one year of target info and return target dataframe array\n",
    "    api = PushshiftAPI()\n",
    "    TargetDfArr = []\n",
    "    \n",
    "    for month in range(1, 13):\n",
    "        if month == 12:\n",
    "            start_epoch=int(dt.datetime(year, month, 2).timestamp())\n",
    "            end_epoch=int(dt.datetime(year + 1, 1, 1).timestamp())\n",
    "        else:\n",
    "            start_epoch=int(dt.datetime(year, month, 2).timestamp())\n",
    "            end_epoch=int(dt.datetime(year, month + 1, 1).timestamp())\n",
    "            \n",
    "        tmpDf = pd.DataFrame(list(api.search_submissions(\n",
    "                            after = str(start_epoch), #start time\n",
    "                            before = str(end_epoch), #end time\n",
    "                            subreddit = 'investing',\n",
    "                            q = target,\n",
    "                            filter = ['author', 'title', 'subreddit', 'score', 'selftext'],\n",
    "                            limit = 10000)))\n",
    "        if len(tmpDf) == 0:\n",
    "            continue\n",
    "            \n",
    "        tmpDf = tmpDf[['created_utc','author','score','title','selftext']]\n",
    "\n",
    "        for i in range(len(tmpDf)):\n",
    "            tmpDf['created_utc'].iloc[i] = time.strftime(\"%Y-%m-%d\", time.gmtime(tmpDf['created_utc'].iloc[i]))\n",
    "        \n",
    "        tmpDf.sort_values(by='created_utc', ignore_index = True)\n",
    "        \n",
    "        TargetDfArr.append(tmpDf)\n",
    "        \n",
    "        print('target : ', target, 'year : ', year, 'month : ', month)\n",
    "    return TargetDfArr\n",
    "\n",
    "def targetDfArrToDf(target, dfArr): # concat dataframe array to one dataframe and sort by date\n",
    "    if len(dfArr) == 0:\n",
    "        return\n",
    "    for i in range(0, len(dfArr) - 1):\n",
    "        dfArr[0] = pd.concat([dfArr[0], dfArr[i + 1]], axis = 0, ignore_index = True)\n",
    "    \n",
    "    dfArr[0].sort_values(by='created_utc', ignore_index = True)\n",
    "    \n",
    "    print('target : ', target, 'has done')\n",
    "    return dfArr[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :   year :  2019 month :  1\n",
      "target :   year :  2019 month :  2\n",
      "target :   year :  2019 month :  3\n",
      "target :   year :  2019 month :  4\n",
      "target :   year :  2019 month :  5\n",
      "target :   year :  2019 month :  6\n",
      "target :   year :  2019 month :  7\n",
      "target :   year :  2019 month :  8\n",
      "target :   year :  2019 month :  9\n",
      "target :   year :  2019 month :  10\n",
      "target :   year :  2019 month :  11\n",
      "target :   year :  2019 month :  12\n",
      "target :   has done\n"
     ]
    }
   ],
   "source": [
    "# Run reddit\n",
    "\n",
    "targetArr = [\n",
    "    ''\n",
    "#     'face recognition',\n",
    "#     'fingerprint recognition',\n",
    "#     'drone',\n",
    "#     'HCI',\n",
    "#     'NLP',\n",
    "#     'ICT',\n",
    "]\n",
    "\n",
    "for target in targetArr:\n",
    "    for year in range(2019, 2020):\n",
    "        dfArr = getTargetDfArr(year, target)\n",
    "        df = targetDfArrToDf(target, dfArr)\n",
    "        df.sort_values(by='created_utc', ignore_index = True)\n",
    "#         df.to_csv(target + '-' + str(year) +'.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>pauldecker</td>\n",
       "      <td>1</td>\n",
       "      <td>Prime Talent Chain, Making the Much-Needed Tra...</td>\n",
       "      <td>Prime Talent Chain (PTC) with the concept of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>Alpha99er_</td>\n",
       "      <td>1</td>\n",
       "      <td>My full list of upcoming industries expected t...</td>\n",
       "      <td>Feel free to comment ones I'm missing and I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>Crazybluehorse</td>\n",
       "      <td>1</td>\n",
       "      <td>Have you ever heard about Security Tokens? (Th...</td>\n",
       "      <td>Since 5 months I am looking into Security Toke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>opencoins</td>\n",
       "      <td>1</td>\n",
       "      <td>Thoughts on tokenizing securities using blockc...</td>\n",
       "      <td>I hear it's much cheaper to tokenize securitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-22</td>\n",
       "      <td>markyu007</td>\n",
       "      <td>1</td>\n",
       "      <td>One of the world's largest crypto exchanges lo...</td>\n",
       "      <td>Blockchain Industries announced it had signed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>jacksonfire13</td>\n",
       "      <td>1</td>\n",
       "      <td>I am looking to further diversify my asset por...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>Imtuso</td>\n",
       "      <td>1</td>\n",
       "      <td>Opinions on investing with blockchain lending ...</td>\n",
       "      <td>Coming from a country where access to vanguard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>Jueban</td>\n",
       "      <td>1</td>\n",
       "      <td>Why was Facebook's Libra killed off? A blockch...</td>\n",
       "      <td>https://www.cnbc.com/2019/12/10/saga-launches-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>Askrypto</td>\n",
       "      <td>1</td>\n",
       "      <td>Over 80 Japanese Banks Collaborate with JP Mor...</td>\n",
       "      <td>[https://askrypto.com/news/2019/12/jp-morgan-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2019-12-05</td>\n",
       "      <td>jklokus</td>\n",
       "      <td>1</td>\n",
       "      <td>Investors Flock to Fintech/Blockchain Startup,...</td>\n",
       "      <td>[https://www.coindesk.com/pompliano-joins-boar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_utc          author  score  \\\n",
       "0    2019-01-31      pauldecker      1   \n",
       "1    2019-01-30      Alpha99er_      1   \n",
       "2    2019-01-27  Crazybluehorse      1   \n",
       "3    2019-01-25       opencoins      1   \n",
       "4    2019-01-22       markyu007      1   \n",
       "..          ...             ...    ...   \n",
       "159  2019-12-23   jacksonfire13      1   \n",
       "160  2019-12-12          Imtuso      1   \n",
       "161  2019-12-11          Jueban      1   \n",
       "162  2019-12-11        Askrypto      1   \n",
       "163  2019-12-05         jklokus      1   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Prime Talent Chain, Making the Much-Needed Tra...   \n",
       "1    My full list of upcoming industries expected t...   \n",
       "2    Have you ever heard about Security Tokens? (Th...   \n",
       "3    Thoughts on tokenizing securities using blockc...   \n",
       "4    One of the world's largest crypto exchanges lo...   \n",
       "..                                                 ...   \n",
       "159  I am looking to further diversify my asset por...   \n",
       "160  Opinions on investing with blockchain lending ...   \n",
       "161  Why was Facebook's Libra killed off? A blockch...   \n",
       "162  Over 80 Japanese Banks Collaborate with JP Mor...   \n",
       "163  Investors Flock to Fintech/Blockchain Startup,...   \n",
       "\n",
       "                                              selftext  \n",
       "0     Prime Talent Chain (PTC) with the concept of ...  \n",
       "1    Feel free to comment ones I'm missing and I'll...  \n",
       "2    Since 5 months I am looking into Security Toke...  \n",
       "3    I hear it's much cheaper to tokenize securitie...  \n",
       "4    Blockchain Industries announced it had signed ...  \n",
       "..                                                 ...  \n",
       "159                                                     \n",
       "160  Coming from a country where access to vanguard...  \n",
       "161  https://www.cnbc.com/2019/12/10/saga-launches-...  \n",
       "162  [https://askrypto.com/news/2019/12/jp-morgan-b...  \n",
       "163  [https://www.coindesk.com/pompliano-joins-boar...  \n",
       "\n",
       "[164 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all technology info csv\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = r'./Technology_Csv' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    df = df.sort_values(by='created_utc', ignore_index = True)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame = frame.sort_values(by='created_utc', ignore_index = True)\n",
    "frame.to_csv('Technology.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all year csv\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = r'./Year_Csv' # use your path\n",
    "all_files = glob.glob(path + \"/All-*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    df = df.sort_values(by='created_utc', ignore_index = True)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame = frame.sort_values(by='created_utc', ignore_index = True)\n",
    "frame.to_csv('2015-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit739cdca6e79043be8d1a8bcadc93c81e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
